{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Projeto Final ML - Borba e Graicer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzGfmhNBdVc",
        "colab_type": "text"
      },
      "source": [
        "# *Prevendo o sucesso de jogos da Steam*\n",
        "#### Filipe F. Borba  e Guilherme Z. Graicer\n",
        "#### Insper\n",
        "#### Machine Learning, Prof. Fábio Ayres\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AWcHXYfCBp1",
        "colab_type": "text"
      },
      "source": [
        "A indústria dos games é um setor de escala gigantesca. Na verdade, já é [maior do que a indústria cinematográfica e da música combinadas](https://www.bbc.com/news/technology-46746593), com um número aproximado de 2.5 bilhões de gamers espalhados pelo mundo. Não apenas isso, mas apenas [o jogo Fornite faturou $2.4 bilhões em 2018](https://www.businessinsider.com/how-much-money-does-fortnite-make-2019-1). \n",
        "\n",
        "Com isso, verifica-se a importância de se estudar este mercado e entender suas tendências. Empresas grandes como Microsoft, já fazem sua parte nessa indústria, enquanto outras, como Google, estudam meios para entrar nesse setor ([Google Stadia](https://stadia.google.com/) é um exemplo).\n",
        "\n",
        "Estudando o cenário, existem  projetos de machine learning que utilizam informações parecidas, mas com aplicações diferentes do nosso projeto. Temos como exemplo o [GameRatingsPredictor](https:///github.com/RobertoFalconi/GameRatingsPredictor), que visa predizer qual a faixa etária permitida para certos jogos usando Random Forest (e outros modelos de comparação). Outros projetos já visam a recomendação de certos jogos baseados nas afinidades do usuário, como é o caso do sistema da própria Steam, o [Interactive Recommender](https://arstechnica.com/gaming/2019/07/steam-turns-to-ai-to-help-users-find-gems-amid-thousands-of-games/).\n",
        "\n",
        "Assim, gostaríamos de utilizar as técnicas de Machine Learning passadas durante a disciplina para verificar que tipos de jogos são mais atrativos para os jogadores. Para isso, utilizaremos os dados de uma das mais famosas plataformas de jogos, a Steam.\n",
        "\n",
        "# Importando os dados\n",
        "\n",
        "Os dados foram retirados da plataforma Kaggle de um dataset (com boas avaliações dadas pelos usuários), o [Steam Store Games](https://www.kaggle.com/nikdavis/steam-store-games?select=steam.csv). Através de uma análise rápida, pudemos verificar que os dados são de boa qualidade e temos diversas features relevantes para o projeto. Os dados deste dataset são relativamente recentes: vão até maio de 2019, o que também é positivo.\n",
        "\n",
        "Nesta primeira seção, vamos importar as bibliotecas necessárias e carregar os dados.\n",
        "\n",
        "Obs: Este projeto foi feito utilizando o Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rt8oO6qIrT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aqui importamos todas as dependências do projeto\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "\n",
        "# Dependências auxiliares\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "\n",
        "# Permite que os resultados sejam reproduzíveis. Seed de aleatoriedade.\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L34GpciQ1DI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Caso esteja utilizando o Google Colab, será necessário importar o steam.csv para o workspace.\n",
        "Caso esteja rodando o notebook localmente, basta copiar o steam.csv para a mesma pasta do notebook.\n",
        "\n",
        "Aqui, fazemos a leitura do CSV num dataframe Pandas.\n",
        "\"\"\"\n",
        "FILE = 'steam.csv'\n",
        "df = pd.read_csv(FILE)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh7ZtneRTU1o",
        "colab_type": "text"
      },
      "source": [
        "# Explorando o Dataset\n",
        "\n",
        "Nesta seção, estamos tentando entender melhor os dados do dataset de jogos da steam. Buscamos ver a correlação das variáveis, dados faltando, outliers e outras informações importantes acerca do dataset.\n",
        "\n",
        "Primeiro, procuramos entender o tamanho do dataset, os tipos dos dados e o conteúdo de algumas linhas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bLOXAueIrUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "667d9a99-f40a-49d5-fe48-381a0f33b8c7"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27075 entries, 0 to 27074\n",
            "Data columns (total 18 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   appid             27075 non-null  int64  \n",
            " 1   name              27075 non-null  object \n",
            " 2   release_date      27075 non-null  object \n",
            " 3   english           27075 non-null  int64  \n",
            " 4   developer         27075 non-null  object \n",
            " 5   publisher         27075 non-null  object \n",
            " 6   platforms         27075 non-null  object \n",
            " 7   required_age      27075 non-null  int64  \n",
            " 8   categories        27075 non-null  object \n",
            " 9   genres            27075 non-null  object \n",
            " 10  steamspy_tags     27075 non-null  object \n",
            " 11  achievements      27075 non-null  int64  \n",
            " 12  positive_ratings  27075 non-null  int64  \n",
            " 13  negative_ratings  27075 non-null  int64  \n",
            " 14  average_playtime  27075 non-null  int64  \n",
            " 15  median_playtime   27075 non-null  int64  \n",
            " 16  owners            27075 non-null  object \n",
            " 17  price             27075 non-null  float64\n",
            "dtypes: float64(1), int64(8), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ylh0OmIrUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "6d253379-d012-4a84-d999-190dcb7a5511"
      },
      "source": [
        "df.head(n=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appid</th>\n",
              "      <th>name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>english</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>platforms</th>\n",
              "      <th>required_age</th>\n",
              "      <th>categories</th>\n",
              "      <th>genres</th>\n",
              "      <th>steamspy_tags</th>\n",
              "      <th>achievements</th>\n",
              "      <th>positive_ratings</th>\n",
              "      <th>negative_ratings</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>owners</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>Counter-Strike</td>\n",
              "      <td>2000-11-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Online Multi-Player;Local Multi-P...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action;FPS;Multiplayer</td>\n",
              "      <td>0</td>\n",
              "      <td>124534</td>\n",
              "      <td>3339</td>\n",
              "      <td>17612</td>\n",
              "      <td>317</td>\n",
              "      <td>10000000-20000000</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>Team Fortress Classic</td>\n",
              "      <td>1999-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Online Multi-Player;Local Multi-P...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action;FPS;Multiplayer</td>\n",
              "      <td>0</td>\n",
              "      <td>3318</td>\n",
              "      <td>633</td>\n",
              "      <td>277</td>\n",
              "      <td>62</td>\n",
              "      <td>5000000-10000000</td>\n",
              "      <td>3.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30</td>\n",
              "      <td>Day of Defeat</td>\n",
              "      <td>2003-05-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Valve Anti-Cheat enabled</td>\n",
              "      <td>Action</td>\n",
              "      <td>FPS;World War II;Multiplayer</td>\n",
              "      <td>0</td>\n",
              "      <td>3416</td>\n",
              "      <td>398</td>\n",
              "      <td>187</td>\n",
              "      <td>34</td>\n",
              "      <td>5000000-10000000</td>\n",
              "      <td>3.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>Deathmatch Classic</td>\n",
              "      <td>2001-06-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Online Multi-Player;Local Multi-P...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action;FPS;Multiplayer</td>\n",
              "      <td>0</td>\n",
              "      <td>1273</td>\n",
              "      <td>267</td>\n",
              "      <td>258</td>\n",
              "      <td>184</td>\n",
              "      <td>5000000-10000000</td>\n",
              "      <td>3.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>Half-Life: Opposing Force</td>\n",
              "      <td>1999-11-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Gearbox Software</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Multi-player;Valve Anti-Cheat en...</td>\n",
              "      <td>Action</td>\n",
              "      <td>FPS;Action;Sci-fi</td>\n",
              "      <td>0</td>\n",
              "      <td>5250</td>\n",
              "      <td>288</td>\n",
              "      <td>624</td>\n",
              "      <td>415</td>\n",
              "      <td>5000000-10000000</td>\n",
              "      <td>3.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   appid                       name  ...             owners  price\n",
              "0     10             Counter-Strike  ...  10000000-20000000   7.19\n",
              "1     20      Team Fortress Classic  ...   5000000-10000000   3.99\n",
              "2     30              Day of Defeat  ...   5000000-10000000   3.99\n",
              "3     40         Deathmatch Classic  ...   5000000-10000000   3.99\n",
              "4     50  Half-Life: Opposing Force  ...   5000000-10000000   3.99\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qn7UY3RIrUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "552d24c9-7453-4ce9-a9bf-0383ac06dd93"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appid</th>\n",
              "      <th>english</th>\n",
              "      <th>required_age</th>\n",
              "      <th>achievements</th>\n",
              "      <th>positive_ratings</th>\n",
              "      <th>negative_ratings</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.707500e+04</td>\n",
              "      <td>27075.000000</td>\n",
              "      <td>27075.000000</td>\n",
              "      <td>27075.000000</td>\n",
              "      <td>2.707500e+04</td>\n",
              "      <td>27075.000000</td>\n",
              "      <td>27075.000000</td>\n",
              "      <td>27075.00000</td>\n",
              "      <td>27075.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.962035e+05</td>\n",
              "      <td>0.981127</td>\n",
              "      <td>0.354903</td>\n",
              "      <td>45.248864</td>\n",
              "      <td>1.000559e+03</td>\n",
              "      <td>211.027147</td>\n",
              "      <td>149.804949</td>\n",
              "      <td>146.05603</td>\n",
              "      <td>6.078193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.508942e+05</td>\n",
              "      <td>0.136081</td>\n",
              "      <td>2.406044</td>\n",
              "      <td>352.670281</td>\n",
              "      <td>1.898872e+04</td>\n",
              "      <td>4284.938531</td>\n",
              "      <td>1827.038141</td>\n",
              "      <td>2353.88008</td>\n",
              "      <td>7.874922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.012300e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.990700e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.400000e+01</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>3.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.987600e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.260000e+02</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>7.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.069460e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>9821.000000</td>\n",
              "      <td>2.644404e+06</td>\n",
              "      <td>487076.000000</td>\n",
              "      <td>190625.000000</td>\n",
              "      <td>190625.00000</td>\n",
              "      <td>421.990000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              appid       english  ...  median_playtime         price\n",
              "count  2.707500e+04  27075.000000  ...      27075.00000  27075.000000\n",
              "mean   5.962035e+05      0.981127  ...        146.05603      6.078193\n",
              "std    2.508942e+05      0.136081  ...       2353.88008      7.874922\n",
              "min    1.000000e+01      0.000000  ...          0.00000      0.000000\n",
              "25%    4.012300e+05      1.000000  ...          0.00000      1.690000\n",
              "50%    5.990700e+05      1.000000  ...          0.00000      3.990000\n",
              "75%    7.987600e+05      1.000000  ...          0.00000      7.190000\n",
              "max    1.069460e+06      1.000000  ...     190625.00000    421.990000\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfJTC1zkkets",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "aa077350-3e80-4260-8372-560907d15e2f"
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appid</th>\n",
              "      <th>english</th>\n",
              "      <th>required_age</th>\n",
              "      <th>achievements</th>\n",
              "      <th>positive_ratings</th>\n",
              "      <th>negative_ratings</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>appid</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.116878</td>\n",
              "      <td>-0.087740</td>\n",
              "      <td>0.040510</td>\n",
              "      <td>-0.070888</td>\n",
              "      <td>-0.052198</td>\n",
              "      <td>-0.070236</td>\n",
              "      <td>-0.048308</td>\n",
              "      <td>-0.152112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>english</th>\n",
              "      <td>-0.116878</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002860</td>\n",
              "      <td>0.014121</td>\n",
              "      <td>0.006001</td>\n",
              "      <td>0.005705</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>-0.003416</td>\n",
              "      <td>0.007716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>required_age</th>\n",
              "      <td>-0.087740</td>\n",
              "      <td>0.002860</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.005459</td>\n",
              "      <td>0.060418</td>\n",
              "      <td>0.057599</td>\n",
              "      <td>0.034423</td>\n",
              "      <td>0.014748</td>\n",
              "      <td>0.120358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achievements</th>\n",
              "      <td>0.040510</td>\n",
              "      <td>0.014121</td>\n",
              "      <td>-0.005459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006058</td>\n",
              "      <td>0.003578</td>\n",
              "      <td>0.014175</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>-0.007996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive_ratings</th>\n",
              "      <td>-0.070888</td>\n",
              "      <td>0.006001</td>\n",
              "      <td>0.060418</td>\n",
              "      <td>0.006058</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.762804</td>\n",
              "      <td>0.157898</td>\n",
              "      <td>0.035776</td>\n",
              "      <td>0.036110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative_ratings</th>\n",
              "      <td>-0.052198</td>\n",
              "      <td>0.005705</td>\n",
              "      <td>0.057599</td>\n",
              "      <td>0.003578</td>\n",
              "      <td>0.762804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.161140</td>\n",
              "      <td>0.047887</td>\n",
              "      <td>0.051259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_playtime</th>\n",
              "      <td>-0.070236</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.034423</td>\n",
              "      <td>0.014175</td>\n",
              "      <td>0.157898</td>\n",
              "      <td>0.161140</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.914900</td>\n",
              "      <td>0.049242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median_playtime</th>\n",
              "      <td>-0.048308</td>\n",
              "      <td>-0.003416</td>\n",
              "      <td>0.014748</td>\n",
              "      <td>0.009957</td>\n",
              "      <td>0.035776</td>\n",
              "      <td>0.047887</td>\n",
              "      <td>0.914900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.036610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>-0.152112</td>\n",
              "      <td>0.007716</td>\n",
              "      <td>0.120358</td>\n",
              "      <td>-0.007996</td>\n",
              "      <td>0.036110</td>\n",
              "      <td>0.051259</td>\n",
              "      <td>0.049242</td>\n",
              "      <td>0.036610</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     appid   english  ...  median_playtime     price\n",
              "appid             1.000000 -0.116878  ...        -0.048308 -0.152112\n",
              "english          -0.116878  1.000000  ...        -0.003416  0.007716\n",
              "required_age     -0.087740  0.002860  ...         0.014748  0.120358\n",
              "achievements      0.040510  0.014121  ...         0.009957 -0.007996\n",
              "positive_ratings -0.070888  0.006001  ...         0.035776  0.036110\n",
              "negative_ratings -0.052198  0.005705  ...         0.047887  0.051259\n",
              "average_playtime -0.070236  0.000338  ...         0.914900  0.049242\n",
              "median_playtime  -0.048308 -0.003416  ...         1.000000  0.036610\n",
              "price            -0.152112  0.007716  ...         0.036610  1.000000\n",
              "\n",
              "[9 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah-IXW7XIrU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "ef40e7f4-98d4-4d33-c9b6-6b147ff55f65"
      },
      "source": [
        "df.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m7mDtAvKUxl",
        "colab_type": "text"
      },
      "source": [
        "Numa análise preliminar, podemos verificar que o dataset conta com algumas variáveis que precisam de tratamento e outras inúteis. O interessante aqui é que as variáveis são bastante concentradas em alguns valores (`price`, por exemplo) e outras são categóricas apesar de seu conteúdo serem números (`english`, por exemplo). Além disso, os histogramas não mostram muitas informações relevantes, pois existem outliers (poucos números com valores muito altos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxHuUJpoPoAd",
        "colab_type": "text"
      },
      "source": [
        "Na célula a seguir, é possível verificar a similaridade das colunas `categories, genres e steamspy_tags`. As três procuram definir melhor o tipo de jogo e serão explicadas mais para frente quando formos preparar o dataset para uso. Precisamos transformar essas características em features para o nosso modelo.\n",
        "\n",
        "Observando as colunas `developer` e `publisher`, constatamos que podemos ter diversos Developers e Publishers diferentes para um mesmo jogo, então também precisamos transformá-los em features para o nosso modelo. Essa operação será explicada mais adiante.\n",
        "\n",
        "A coluna `platforms` tem apenas uma combinação de `windows`, `mac` ou `linux` como possíveis valores.\n",
        "\n",
        "Todas as *features*  citadas aqui são categóricas e serão terão que passar por uma espécie de *encoder* para entrar no modelo. Isso transformará, cada categoria delas em uma *feature* própria valendo 0 ou 1 de acordo com sua presença no jogo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swnEO1tTMYHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "0c6f41f5-aa82-41ad-e18a-67f9dc914331"
      },
      "source": [
        "pd.concat([df.iloc[23:26], df.iloc[149:151]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appid</th>\n",
              "      <th>name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>english</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>platforms</th>\n",
              "      <th>required_age</th>\n",
              "      <th>categories</th>\n",
              "      <th>genres</th>\n",
              "      <th>steamspy_tags</th>\n",
              "      <th>achievements</th>\n",
              "      <th>positive_ratings</th>\n",
              "      <th>negative_ratings</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>owners</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>620</td>\n",
              "      <td>Portal 2</td>\n",
              "      <td>2011-04-18</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Co-op;Steam Achievements;Full co...</td>\n",
              "      <td>Action;Adventure</td>\n",
              "      <td>Puzzle;Co-op;First-Person</td>\n",
              "      <td>51</td>\n",
              "      <td>138220</td>\n",
              "      <td>1891</td>\n",
              "      <td>1102</td>\n",
              "      <td>520</td>\n",
              "      <td>10000000-20000000</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>630</td>\n",
              "      <td>Alien Swarm</td>\n",
              "      <td>2010-07-19</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Multi-player;Co-op;Steam Achieve...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Free to Play;Co-op;Action</td>\n",
              "      <td>66</td>\n",
              "      <td>17435</td>\n",
              "      <td>941</td>\n",
              "      <td>371</td>\n",
              "      <td>83</td>\n",
              "      <td>2000000-5000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>730</td>\n",
              "      <td>Counter-Strike: Global Offensive</td>\n",
              "      <td>2012-08-21</td>\n",
              "      <td>1</td>\n",
              "      <td>Valve;Hidden Path Entertainment</td>\n",
              "      <td>Valve</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Steam Achievements;Full controlle...</td>\n",
              "      <td>Action;Free to Play</td>\n",
              "      <td>FPS;Multiplayer;Shooter</td>\n",
              "      <td>167</td>\n",
              "      <td>2644404</td>\n",
              "      <td>402313</td>\n",
              "      <td>22494</td>\n",
              "      <td>6502</td>\n",
              "      <td>50000000-100000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>6020</td>\n",
              "      <td>STAR WARS™ Jedi Knight - Jedi Academy™</td>\n",
              "      <td>2009-09-16</td>\n",
              "      <td>1</td>\n",
              "      <td>Raven Software;Aspyr (Mac)</td>\n",
              "      <td>LucasArts;Aspyr (Mac);Lucasfilm;Disney Interac...</td>\n",
              "      <td>windows;mac</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Online Multi-Player;Local Multi-...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Star Wars;Action;Sci-fi</td>\n",
              "      <td>0</td>\n",
              "      <td>5684</td>\n",
              "      <td>330</td>\n",
              "      <td>1254</td>\n",
              "      <td>174</td>\n",
              "      <td>1000000-2000000</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>6030</td>\n",
              "      <td>STAR WARS™ Jedi Knight II - Jedi Outcast™</td>\n",
              "      <td>2009-09-16</td>\n",
              "      <td>1</td>\n",
              "      <td>Raven Software;Aspyr (Mac)</td>\n",
              "      <td>LucasArts;Aspyr (Mac);Lucasfilm;Disney Interac...</td>\n",
              "      <td>windows;mac</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Online Multi-Player;Local Multi-...</td>\n",
              "      <td>Action</td>\n",
              "      <td>Star Wars;Action;Classic</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>219</td>\n",
              "      <td>127</td>\n",
              "      <td>180</td>\n",
              "      <td>1000000-2000000</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     appid  ... price\n",
              "23     620  ...  7.19\n",
              "24     630  ...  0.00\n",
              "25     730  ...  0.00\n",
              "149   6020  ...  7.19\n",
              "150   6030  ...  7.19\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "794KvCe30_3A",
        "colab_type": "text"
      },
      "source": [
        "# Preparando o Dataset\n",
        "\n",
        "Após analisar o dataset sem realizar modificações, vamos tratá-lo, adicionando algumas colunas importantes para o treinamento e removendo outras que são irrelevantes. A primeira que vamos adicionar é a `positive_rate` que representa a porcentagem de avaliações positivas nos jogos. Utilizaremos essa métrica como variável dependente do nosso projeto, pois queremos descobrir como ela interage com as outras e prever ela de acordo com as outras. Essa métrica é comum na loja da Steam para indicar jogos bem avaliados pelos jogadores.\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "  <a href=\"https://i.imgur.com/WcyTDHw.png?1\">\n",
        "  <img src=\"https://i.imgur.com/WcyTDHw.png?1\" alt=\"CSGO Positive Reviews Jun 09 - 2020\" height=\"200\" />\n",
        "  </a>\n",
        "  <figcaption>Página da loja da Steam com as avaliações do jogo Counter-Strike: Global Offensive - Clique para aumentar</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "Além disso, como verificado, as colunas `categories, genres e steamspy_tags` são similares. A coluna `categories` indica filtros utilizados pela loja da Steam para agrupar certos jogos, com categorias específicas e genéricas ao mesmo tempo, muitas vezes tendo valores irrelevantes ou valores que não são comuns a todos os dados. A coluna `genres` possui uma definição do tipo do jogo mais clara, porém mais generalista (ex: Ação). Por fim, a coluna `steamspy_tags` contém rotulagens (tags) feitas por usuários no site SteamSpy. Os usuários votam nas tags que melhor representam cada jogo, assim, quanto mais votos, melhor associada a tag é com o jogo. Com isso, podemos apurar melhor o tipo de jogo, contendo informações comuns a todos os jogos e abrangentes o suficiente para definir melhor tipo. Assim, podemos descartar `categories` e manter as outras duas colunas para nosso projeto.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAxzfJoLIEjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f95e7786-eb0b-4ad3-a94f-127798239917"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['appid', 'name', 'release_date', 'english', 'developer', 'publisher',\n",
              "       'platforms', 'required_age', 'categories', 'genres', 'steamspy_tags',\n",
              "       'achievements', 'positive_ratings', 'negative_ratings',\n",
              "       'average_playtime', 'median_playtime', 'owners', 'price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFTDruvHVZ41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "414ec62a-d1ee-4692-c526-8747a00d807d"
      },
      "source": [
        "df['positive_rate'] = df['positive_ratings'] / (df['positive_ratings']+df['negative_ratings'])\n",
        "df['positive_rate'].head(n=5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.973888\n",
              "1    0.839787\n",
              "2    0.895648\n",
              "3    0.826623\n",
              "4    0.947996\n",
              "Name: positive_rate, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jpbuyFHQRY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# platforms\n",
        "\n",
        "# df_platforms = df['platforms'].str.get_dummies(';')\n",
        "# df_platforms = df_platforms.add_prefix('platform_')\n",
        "# df_platforms.head(n=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW51gVI-QgEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# steamspy_tags\n",
        "\n",
        "# df_steamspy_tags = df['steamspy_tags'].str.get_dummies(';')\n",
        "# df_steamspy_tags = df_steamspy_tags.add_prefix('tags_')\n",
        "# df_steamspy_tags.head(n=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgrOihM2QwlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# genres\n",
        "\n",
        "# df_genres = df['genres'].str.get_dummies(';')\n",
        "# df_genres = df_genres.add_prefix('genres_')\n",
        "# df_genres.head(n=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hthq5W7HQ2_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# owners\n",
        "\n",
        "# df_owners = df['owners'].str.get_dummies(';')\n",
        "# df_owners = df_owners.add_prefix('owners_')\n",
        "# df_owners.head(n=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsYvS-w4RgGF",
        "colab_type": "text"
      },
      "source": [
        "### `publisher & developer`\n",
        "\n",
        "Existe um problema aqui, a quantidade de publishers e developers diferentes é tão grande que inviabiliza a criação de uma coluna para cada.\n",
        "Ademais, a maioria deles só estão ligados a um jogo. \n",
        "Para resolver isso, os nomes dos publishers e developers que tem somente um jogo foram substituidos por \"Outros\".\n",
        "\n",
        "Com isso, utilizamos a função get_dummies do pandas para transformar essas duas colunas em diversas colunas de features. Cada publisher & developer individualmente se torna uma nova coluna com valor 0 ou 1 para indicar sua presença no jogo.\n",
        "\n",
        "Isso torna-se uma limitação do nosso modelo, mas foi a maneira achada para usar essa variavel categórica, visto que aumentamos o número de features drasticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCQh48hoQ5VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pub_counts = Counter([v.strip() for x in df['publisher'] for v in x.strip().split(';')])\n",
        "pub_list = sorted(((v, k) for k, v in pub_counts.items()), reverse=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OMfjoXsRt5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_counts = Counter([v.strip() for x in df['developer'] for v in x.strip().split(';')])\n",
        "dev_list = sorted(((v, k) for k, v in dev_counts.items()), reverse=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wenB-AEaRVea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "982a4eb4-1a7f-475e-cea1-e88e9e1153fd"
      },
      "source": [
        "one_game_pubs = []\n",
        "one_game_devs = []\n",
        "for i in range(len(pub_list)):\n",
        "  if pub_list[i][0] == 1:\n",
        "    one_game_pubs.append(pub_list[i][1])\n",
        "\n",
        "for i in range(len(dev_list)):\n",
        "  if dev_list[i][0] == 1:\n",
        "    one_game_devs.append(dev_list[i][1])\n",
        "                         \n",
        "print(f\"Número total de publishers diferentes: {len(pub_list)}\")\n",
        "print(f\"Quantidade deles que estão ligados a somente um jogo: {len(one_game_pubs)}\")\n",
        "print()\n",
        "\n",
        "print(f\"Número total de developers diferentes: {len(dev_list)}\")\n",
        "print(f\"Quantidade deles que estão ligados a somente um jogo: {len(one_game_devs)}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número total de publishers diferentes: 14238\n",
            "Quantidade deles que estão ligados a somente um jogo: 10840\n",
            "\n",
            "Número total de developers diferentes: 17952\n",
            "Quantidade deles que estão ligados a somente um jogo: 13671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgwDMvs3RWVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_one_game_pubs(s):\n",
        "  \"\"\"\n",
        "  Função que recebe a string de publishers e devolve mascarando os que tem somente um jogo,\n",
        "  chamando-os de 'outros'\n",
        "\n",
        "  args: string da célula da coluna Publishers\n",
        "  output: string 'mascarada'\n",
        "  \"\"\"\n",
        "  \n",
        "  game_pub_list = [v.strip() for v in s.strip().split(';')]\n",
        "  for i, pub in enumerate(game_pub_list):\n",
        "    if pub in one_game_pubs:\n",
        "      game_pub_list[i] = 'others'\n",
        "  \n",
        "  game_pub_set = set(game_pub_list)\n",
        "\n",
        "  new_s = \"\"\n",
        "\n",
        "  for e in game_pub_set:\n",
        "    new_s += e\n",
        "    new_s += \";\"\n",
        "  new_s = new_s[:-1]\n",
        "\n",
        "  return new_s\n",
        "\n",
        "def replace_one_game_devs(s):\n",
        "  \"\"\"\n",
        "  Função que recebe a string de developers e devolve mascarando os que tem somente um jogo,\n",
        "  chamando-os de 'outros'\n",
        "\n",
        "  args: string da célula da coluna Developer\n",
        "  output: string 'mascarada'\n",
        "  \"\"\"\n",
        "  game_dev_list = [v.strip() for v in s.strip().split(';')]\n",
        "  for i, dev in enumerate(game_dev_list):\n",
        "    if dev in one_game_devs:\n",
        "      game_dev_list[i] = 'others'\n",
        "  \n",
        "  game_dev_set = set(game_dev_list)\n",
        "\n",
        "  new_s = \"\"\n",
        "\n",
        "  for e in game_dev_set:\n",
        "    new_s += e\n",
        "    new_s += \";\"\n",
        "  new_s = new_s[:-1]\n",
        "\n",
        "  return new_s"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKBDz_C0RYjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aplicando a função acima a todas as colunas do dataframe\n",
        "df['publisher'] = df['publisher'].apply(lambda x: replace_one_game_pubs(x))\n",
        "\n",
        "# Aplicando a função acima a todas as colunas do dataframe\n",
        "df['developer'] = df['developer'].apply(lambda x: replace_one_game_devs(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4mQE8LYRarW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agora sim, cria-se um dataframe com uma coluna por publisher\n",
        "# df_publisher = df['publisher'].str.get_dummies(';')\n",
        "# df_publisher = df_publisher.add_prefix('pub_')\n",
        "# df_publisher.head()\n",
        "\n",
        "# df_developer = df['developer'].str.get_dummies(';')\n",
        "# df_developer = df_developer.add_prefix('dev_')\n",
        "# df_developer.head()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBYId14-SYl1",
        "colab_type": "text"
      },
      "source": [
        "Com todos os dataframes de variáveis tratados, basta concatená-los ao dataframe original, removendo as colunas dessas categorias. Além disso, foram removidas as outras categorias irrelevantes para o treinamento:\n",
        "- `positive_ratings & negative_ratings`: já foram usados para estabelecer o `positive_rate` \n",
        "- `appid`: apenas um identificador, é irrelevante.\n",
        "- `name` e `release_date`: irrelevantes para o treinamento do modelo\n",
        "- `platform, publishers, developers, steamspy_tags, owners, required_age`: todas transformadas com o get_dummies, sem necessidade de mantê-los.\n",
        "\n",
        "Uma observação importante é que para cada dummy das categorias utilizadas, adicionamos um prefixo (referente a *feature* original de onde pertencia essa categoria) para facilitar a identificação no momento da análise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xIH7KfCoSvx",
        "colab_type": "text"
      },
      "source": [
        "### Dataset tratado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a9a-aI7STJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.concat([df, df_platforms, df_steamspy_tags, df_genres, df_publisher,df_developer, df_owners], axis=1).drop(columns=['name', 'release_date', 'appid', 'developer', 'publisher', 'platforms', 'categories', 'genres', 'steamspy_tags', 'positive_ratings', 'negative_ratings', 'owners'])\n",
        "# tudo que foi comentado nas células acima está na linha abaixo, para evitar a criação de vários DataFrames e o consumo exessivo de RAM"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORvVEzbhb5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([df, df['platforms'].str.get_dummies(';').add_prefix('platform_'), df['steamspy_tags'].str.get_dummies(';').add_prefix('tags_'), df['genres'].str.get_dummies(';').add_prefix('genres_'), df['publisher'].str.get_dummies(';').add_prefix('pub_'), df['developer'].str.get_dummies(';').add_prefix('dev_'), df['owners'].str.get_dummies(';').add_prefix('owners_'), df['required_age'].apply(str).str.get_dummies(';').add_prefix('age_')], axis=1).drop(columns=['name', 'release_date', 'appid', 'developer', 'publisher', 'platforms', 'categories', 'genres', 'steamspy_tags', 'positive_ratings', 'negative_ratings', 'owners', 'required_age'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJTV-FWbQJ6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d55456fa-533f-43c2-c207-af04fa7bf0b3"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27075 entries, 0 to 27074\n",
            "Columns: 8076 entries, english to age_7\n",
            "dtypes: float64(2), int64(8074)\n",
            "memory usage: 1.6 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw5HvZUGg7By",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('worked_df.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo2zEG36lq1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('worked_df.csv', index_col=[0])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbaSw2RFentt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "cd9894e9-b0a7-4fa6-e252-684ba65acbcb"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>achievements</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>price</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>platform_linux</th>\n",
              "      <th>platform_mac</th>\n",
              "      <th>platform_windows</th>\n",
              "      <th>tags_1980s</th>\n",
              "      <th>tags_1990's</th>\n",
              "      <th>tags_2.5D</th>\n",
              "      <th>tags_2D</th>\n",
              "      <th>tags_2D Fighter</th>\n",
              "      <th>tags_360 Video</th>\n",
              "      <th>tags_3D</th>\n",
              "      <th>tags_3D Platformer</th>\n",
              "      <th>tags_3D Vision</th>\n",
              "      <th>tags_4 Player Local</th>\n",
              "      <th>tags_4X</th>\n",
              "      <th>tags_6DOF</th>\n",
              "      <th>tags_Abstract</th>\n",
              "      <th>tags_Action</th>\n",
              "      <th>tags_Action RPG</th>\n",
              "      <th>tags_Action-Adventure</th>\n",
              "      <th>tags_Adventure</th>\n",
              "      <th>tags_Agriculture</th>\n",
              "      <th>tags_Aliens</th>\n",
              "      <th>tags_Alternate History</th>\n",
              "      <th>tags_America</th>\n",
              "      <th>tags_Animation &amp; Modeling</th>\n",
              "      <th>tags_Anime</th>\n",
              "      <th>tags_Arcade</th>\n",
              "      <th>tags_Arena Shooter</th>\n",
              "      <th>tags_Assassin</th>\n",
              "      <th>tags_Atmospheric</th>\n",
              "      <th>tags_Audio Production</th>\n",
              "      <th>tags_BMX</th>\n",
              "      <th>tags_Base-Building</th>\n",
              "      <th>tags_Baseball</th>\n",
              "      <th>...</th>\n",
              "      <th>dev_吃了就睡工作室</th>\n",
              "      <th>dev_哈视奇科技</th>\n",
              "      <th>dev_大好网</th>\n",
              "      <th>dev_威震天科技</th>\n",
              "      <th>dev_小戴的奴隶们</th>\n",
              "      <th>dev_木子工坊</th>\n",
              "      <th>dev_朵游社</th>\n",
              "      <th>dev_梵天游戏</th>\n",
              "      <th>dev_橘喵喵</th>\n",
              "      <th>dev_橘子班</th>\n",
              "      <th>dev_橙光游戏</th>\n",
              "      <th>dev_灰烬天国</th>\n",
              "      <th>dev_热泉 RedSpring</th>\n",
              "      <th>dev_甲山林娛樂股份有限公司</th>\n",
              "      <th>dev_疯王子</th>\n",
              "      <th>dev_绚丽奈落</th>\n",
              "      <th>dev_自由愉悦小黄猫(Free pleasure little yellow cat)</th>\n",
              "      <th>dev_致意</th>\n",
              "      <th>dev_迷茫的菜鸟</th>\n",
              "      <th>dev_阿达游戏</th>\n",
              "      <th>dev_黄昏フロンティア</th>\n",
              "      <th>owners_0-20000</th>\n",
              "      <th>owners_100000-200000</th>\n",
              "      <th>owners_1000000-2000000</th>\n",
              "      <th>owners_10000000-20000000</th>\n",
              "      <th>owners_100000000-200000000</th>\n",
              "      <th>owners_20000-50000</th>\n",
              "      <th>owners_200000-500000</th>\n",
              "      <th>owners_2000000-5000000</th>\n",
              "      <th>owners_20000000-50000000</th>\n",
              "      <th>owners_50000-100000</th>\n",
              "      <th>owners_500000-1000000</th>\n",
              "      <th>owners_5000000-10000000</th>\n",
              "      <th>owners_50000000-100000000</th>\n",
              "      <th>age_0</th>\n",
              "      <th>age_12</th>\n",
              "      <th>age_16</th>\n",
              "      <th>age_18</th>\n",
              "      <th>age_3</th>\n",
              "      <th>age_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17612</td>\n",
              "      <td>317</td>\n",
              "      <td>7.19</td>\n",
              "      <td>0.973888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>277</td>\n",
              "      <td>62</td>\n",
              "      <td>3.99</td>\n",
              "      <td>0.839787</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>34</td>\n",
              "      <td>3.99</td>\n",
              "      <td>0.895648</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>258</td>\n",
              "      <td>184</td>\n",
              "      <td>3.99</td>\n",
              "      <td>0.826623</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>624</td>\n",
              "      <td>415</td>\n",
              "      <td>3.99</td>\n",
              "      <td>0.947996</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 8076 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   english  achievements  average_playtime  ...  age_18  age_3  age_7\n",
              "0        1             0             17612  ...       0      0      0\n",
              "1        1             0               277  ...       0      0      0\n",
              "2        1             0               187  ...       0      0      0\n",
              "3        1             0               258  ...       0      0      0\n",
              "4        1             0               624  ...       0      0      0\n",
              "\n",
              "[5 rows x 8076 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMET3i9DohXJ",
        "colab_type": "text"
      },
      "source": [
        "Agora temos um dataset totalmente tratado, com as variáveis categóricas incorporadas e variáveis inúteis removidas. Está na hora de dividir os dados em treinamento e testes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKEMKB0lj0Ci",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Dividindo os dados em conjunto de treinamento e de testes (estratificado)\n",
        "Para dividir os dados em treinamento e teste, precisamos fazer uma divisão estratificada deles. Ou seja, a proporção da variável dependente entre os sets de treinamento e teste devem ser parecidas.\n",
        "\n",
        "Para garantir isso, foi feita uma coluna nova no dataframe (rate_cat) que divide os jogos em 5 categorias, uma para cada quinto entre 0 e 100%. A divisão estratificada foi feita com base nessa nova categoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m42fcvIBSsMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constroi uma coluna nova com categorias de positive_negative_rate fictícias.\n",
        "df['rate_cat'] = np.round(df['positive_rate']*100 / 20)\n",
        "# housing['rate_cat'].where(housing['rate_cat'] < 5, 5.0, inplace=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp5lwJT1GZeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divide, de modo estratificado, o conjunto de dados.\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
        "for train_index, test_index in split.split(df, df[\"rate_cat\"]):\n",
        "    strat_train_set = df.loc[train_index]\n",
        "    strat_test_set = df.loc[test_index]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqzEwRcpGdoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1dc3a8d2-8202-4d06-d329-aa0316ec9d07"
      },
      "source": [
        "strat_train_set['rate_cat'].value_counts() / len(strat_train_set)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    0.366851\n",
              "5.0    0.235365\n",
              "3.0    0.207525\n",
              "2.0    0.130286\n",
              "1.0    0.033841\n",
              "0.0    0.026131\n",
              "Name: rate_cat, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUc2fhuFHubB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e1191973-7bd5-4e07-d032-bf50ab57756c"
      },
      "source": [
        "strat_test_set['rate_cat'].value_counts() / len(strat_test_set)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    0.366759\n",
              "5.0    0.235272\n",
              "3.0    0.207572\n",
              "2.0    0.130379\n",
              "1.0    0.033795\n",
              "0.0    0.026223\n",
              "Name: rate_cat, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLwp0dUfH0vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove a coluna nova, que foi adicionada apenas temporariamente.\n",
        "strat_train_set.drop(['rate_cat'], axis=1, inplace=True)\n",
        "strat_test_set.drop(['rate_cat'], axis=1, inplace=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsAbptENLMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k08v3HxcJesz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "e0bd2096-2d2f-43a7-f3f0-e20b1cfff281"
      },
      "source": [
        "strat_test_set"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>achievements</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>median_playtime</th>\n",
              "      <th>price</th>\n",
              "      <th>positive_rate</th>\n",
              "      <th>platform_linux</th>\n",
              "      <th>platform_mac</th>\n",
              "      <th>platform_windows</th>\n",
              "      <th>tags_1980s</th>\n",
              "      <th>tags_1990's</th>\n",
              "      <th>tags_2.5D</th>\n",
              "      <th>tags_2D</th>\n",
              "      <th>tags_2D Fighter</th>\n",
              "      <th>tags_360 Video</th>\n",
              "      <th>tags_3D</th>\n",
              "      <th>tags_3D Platformer</th>\n",
              "      <th>tags_3D Vision</th>\n",
              "      <th>tags_4 Player Local</th>\n",
              "      <th>tags_4X</th>\n",
              "      <th>tags_6DOF</th>\n",
              "      <th>tags_Abstract</th>\n",
              "      <th>tags_Action</th>\n",
              "      <th>tags_Action RPG</th>\n",
              "      <th>tags_Action-Adventure</th>\n",
              "      <th>tags_Adventure</th>\n",
              "      <th>tags_Agriculture</th>\n",
              "      <th>tags_Aliens</th>\n",
              "      <th>tags_Alternate History</th>\n",
              "      <th>tags_America</th>\n",
              "      <th>tags_Animation &amp; Modeling</th>\n",
              "      <th>tags_Anime</th>\n",
              "      <th>tags_Arcade</th>\n",
              "      <th>tags_Arena Shooter</th>\n",
              "      <th>tags_Assassin</th>\n",
              "      <th>tags_Atmospheric</th>\n",
              "      <th>tags_Audio Production</th>\n",
              "      <th>tags_BMX</th>\n",
              "      <th>tags_Base-Building</th>\n",
              "      <th>tags_Baseball</th>\n",
              "      <th>...</th>\n",
              "      <th>dev_吃了就睡工作室</th>\n",
              "      <th>dev_哈视奇科技</th>\n",
              "      <th>dev_大好网</th>\n",
              "      <th>dev_威震天科技</th>\n",
              "      <th>dev_小戴的奴隶们</th>\n",
              "      <th>dev_木子工坊</th>\n",
              "      <th>dev_朵游社</th>\n",
              "      <th>dev_梵天游戏</th>\n",
              "      <th>dev_橘喵喵</th>\n",
              "      <th>dev_橘子班</th>\n",
              "      <th>dev_橙光游戏</th>\n",
              "      <th>dev_灰烬天国</th>\n",
              "      <th>dev_热泉 RedSpring</th>\n",
              "      <th>dev_甲山林娛樂股份有限公司</th>\n",
              "      <th>dev_疯王子</th>\n",
              "      <th>dev_绚丽奈落</th>\n",
              "      <th>dev_自由愉悦小黄猫(Free pleasure little yellow cat)</th>\n",
              "      <th>dev_致意</th>\n",
              "      <th>dev_迷茫的菜鸟</th>\n",
              "      <th>dev_阿达游戏</th>\n",
              "      <th>dev_黄昏フロンティア</th>\n",
              "      <th>owners_0-20000</th>\n",
              "      <th>owners_100000-200000</th>\n",
              "      <th>owners_1000000-2000000</th>\n",
              "      <th>owners_10000000-20000000</th>\n",
              "      <th>owners_100000000-200000000</th>\n",
              "      <th>owners_20000-50000</th>\n",
              "      <th>owners_200000-500000</th>\n",
              "      <th>owners_2000000-5000000</th>\n",
              "      <th>owners_20000000-50000000</th>\n",
              "      <th>owners_50000-100000</th>\n",
              "      <th>owners_500000-1000000</th>\n",
              "      <th>owners_5000000-10000000</th>\n",
              "      <th>owners_50000000-100000000</th>\n",
              "      <th>age_0</th>\n",
              "      <th>age_12</th>\n",
              "      <th>age_16</th>\n",
              "      <th>age_18</th>\n",
              "      <th>age_3</th>\n",
              "      <th>age_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4787</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.59</td>\n",
              "      <td>0.904762</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15124</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9248</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>309</td>\n",
              "      <td>324</td>\n",
              "      <td>44.99</td>\n",
              "      <td>0.564729</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15876</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.99</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4873</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>245</td>\n",
              "      <td>276</td>\n",
              "      <td>14.99</td>\n",
              "      <td>0.884898</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12303</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.99</td>\n",
              "      <td>0.816754</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13995</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.99</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16036</th>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>9.29</td>\n",
              "      <td>0.797382</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>188</td>\n",
              "      <td>146</td>\n",
              "      <td>9.99</td>\n",
              "      <td>0.862047</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8658</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5415 rows × 8076 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       english  achievements  average_playtime  ...  age_18  age_3  age_7\n",
              "4787         1            18                 0  ...       0      0      0\n",
              "15124        1             0                 0  ...       0      0      0\n",
              "9248         1            35               309  ...       1      0      0\n",
              "15876        1            15                 0  ...       0      0      0\n",
              "4873         1            50               245  ...       1      0      0\n",
              "...        ...           ...               ...  ...     ...    ...    ...\n",
              "12303        1            15                 0  ...       0      0      0\n",
              "13995        1            12                 0  ...       0      0      0\n",
              "16036        1            81                45  ...       0      0      0\n",
              "1256         1            12               188  ...       0      0      0\n",
              "8658         1            25                 0  ...       0      0      0\n",
              "\n",
              "[5415 rows x 8076 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Sn_9SVj7-C",
        "colab_type": "text"
      },
      "source": [
        "### Separando X e y\n",
        "Após separar os sets de treinamento e teste, queremos dividir as labels (y) das features (X)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU6TUL5ELwOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variáveis independentes: dataset original menos a coluna de valores dependentes.\n",
        "steam = strat_train_set.drop([\"positive_rate\"], axis=1)\n",
        "\n",
        "# Variável dependente, também chamada de label.\n",
        "steam_labels = strat_train_set[\"positive_rate\"].copy()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOpHx0Q7NhzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5af9c837-5120-481b-a624-ca0963353352"
      },
      "source": [
        "steam_labels #são os positive_rates"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14854    1.000000\n",
              "9552     0.898876\n",
              "3991     0.512821\n",
              "12574    0.416667\n",
              "4837     0.675000\n",
              "           ...   \n",
              "2101     0.513174\n",
              "4007     0.900662\n",
              "12592    0.875000\n",
              "14847    0.608696\n",
              "18645    0.444444\n",
              "Name: positive_rate, Length: 21660, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqUZ29TlIOUE",
        "colab_type": "text"
      },
      "source": [
        "# Definindo modelos\n",
        "\n",
        "\n",
        "Neste projeto, utilizaremos uma série de modelos para realizar as predições das porcentagens de avaliações positivas, a fim de entender quais modelos mais se adequam ao problema e fazer análises mais profundas. Para isso, é feita uma validação onde compara-se o RMSE desses modelos, afim de achar o que gera o menor valor.\n",
        "\n",
        "Obs.: Uma limitação do nosso projeto é que não conseguimos fazer uma validação cruzada nem um ajuste de hiperparâmetros, pois o `cross_val` e o `GridSearchCV` não rodam por falta de RAM. No lugar disso foi feita uma validação simples e um ajuste manual de um parâmetro (o da regularização)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TP271lbQDXR",
        "colab_type": "text"
      },
      "source": [
        "### Decision Trees\n",
        "\n",
        "Um dos algoritmos propostos será o de Decision Trees: um algoritmo de Machine Learning bastante versátil, que pode realizar tanto tarefas de classificação quanto regressão, além de tarefas com outputs múltiplos, com datasets bastante complexos. As Decision Trees também são componentes fundamentais das Random Forests, que estão entre os algoritmos de Machine Learning mais poderosos atualmente.\n",
        "\n",
        "Mas como esses algoritmos funcionam? As Decision Trees utilizam o chamado CART (ou Classification And Regression Tree) para realizar o treinamento. A ideia dele é basicamente dividir o set de treinamento usando uma feature e um threshold para tentar produzir subsets com maior pureza (minimizando, assim, o erro). Com isso, o algoritmo cria bifurcações de **decisões** para diminuir os possíveis resultados. Essa ideia fica mais intuitiva quando observamos a imagem a seguir:\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "  <a href=\"https://i.imgur.com/DCCPl8Y.png\">\n",
        "  <img src=\"https://i.imgur.com/DCCPl8Y.png\" alt=\"Exemplo de Decision Tree usando o famoso Iris dataset\" height=\"300\" />\n",
        "  </a>\n",
        "  <figcaption> Exemplo de Decision Tree usando o famoso Iris dataset - Clique para aumentar</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "Uma das grandes vantagens é que não é necessário escalar as features para a Decision Tree, pois ela não é afetada por isso. Isso acontece, pois ela utiliza somente uma feature por tomada de decisão, nunca comparando mais de uma. Ela vai utilizar os valores da própria feature para compor seus thresholds nos nós. Se ela está tratando com 1000 ou 1, não fará diferença para esse threshould. Assim, podemos dizer que as Decision Trees são modelos não-paramétricos.\n",
        "\n",
        "Um modelo paramétrico, como por exemplo um modelo linear, tem um número pré-determinado de parâmetros, então seus graus de liberdade são limitados, reduzindo o risco de overfitting, mas aumentando o risco de underfitting. Já um modelo não-paramétrico, como o Decision Tree, não possui esse número pré-determinado, mas sim ele tentará se adaptar aos dados, criando uma estrutura própria que o ajude a se manter próximo aos dados. O problema disso é que o risco de overfitting é muito alto, mas há ganhos de simplicidade de treinamento, entre outros. Para diminuir esse risco, é necessário ajustar os hiperparâmetros do modelo, a fim de evitar overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dV2EO-CQEsB",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "Agora, suponha que você pergunte algo complexo para milhares de pessoas aleatórias e agregue suas respostas. Em muitos casos, você vai observar que essa resposta agregada é melhor do que a resposta de um especialista. Isto é chamado de *sabedoria das multidões* (ou *wisdom of the crowds*). \n",
        "\n",
        "De forma similar, se você agregar as predições de um grupo de modelos, você frequentemente sairá com melhores predições do que com apenas um ótimo modelo. Um grupo de preditores é chamado de *ensemble* (ou conjunto); assim, essa técnica é chamada de Ensemble Learning.\n",
        "\n",
        "Este é o caso da famosa Random Forest que discutimos mais cedo. Esse algoritmo nada mais é do que um conjunto de Decision Trees que foram treinadas em subsets aleatórios do nosso set de treinamento. Para fazer as predições, basta obter as predições de todas as árvores individualmente e agregá-las para fazer uma média, no caso de regressão, ou a classe mais votada, no caso de classificação.\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "  <a href=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rfc_vs_dt1.png\">\n",
        "  <img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rfc_vs_dt1.png\" alt=\"Estrutura da Random Forest\" height=\"300\" />\n",
        "  </a>\n",
        "  <figcaption> Estrutura da Random Forest - Clique para aumentar</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "Apesar da sua simplicidade, a Random Forest é um dos algoritmos mais poderosos de Machine Learning disponíveis atualmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7rv2yuUu7q6",
        "colab_type": "text"
      },
      "source": [
        "### Modelos Lineares Regularizados\n",
        "\n",
        "Como visto na definição das Decision Trees, elas possuem um alto risco de *overfitting*, ou seja, ele pode se ajustar tão bem aos dados de treinamento que ajusta-se ao seu ruído, tornando o erro de validação e teste muito mais alto. Para evitar isso, podemos ajustar seus hiperparâmetros. \n",
        "\n",
        "Contudo, precisamos também variar os modelos para medir a qualidade. Para isso, utilizaremos os modelos lineares com e sem regularizações.\n",
        "\n",
        "Uma boa maneira de se reduzir o *overfitting* nesses modelos é regularizando-os. Um exemplo de regularização seria restringi-lo: quanto menos graus de liberdade o modelo tiver, mais dificíl de acontecer *overfit* sobre os dados. Para um modelo linear, a regularização tipicamente é realizada através da restrição dos pesos do modelo.\n",
        "Veremos então as regressões Ridge, Lasso e Elastic Net, que são três implementações diferentes de restrição de pesos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdkcHgMvydeg",
        "colab_type": "text"
      },
      "source": [
        "#### Ridge Regression\n",
        "\n",
        "A regressão Ridge é uma versão regularizada da regressão linear com um *termo de regularização* adicionado à função de custo. Esse termo é dado por \n",
        "\n",
        "$J(\\theta) = MSE(\\theta) +  {\\alpha} {\\sum_{i=1}^{n}} = {{\\theta}^2 _i}$\n",
        "\n",
        "Com $\\theta$ sendo cada amostra do dataset.\n",
        "\n",
        "Isso força o algoritmo de aprendizado não apenas a se adequar aos dados, mas para manter os pesos do modelo o mais baixos possível. É importante notar que o termo de regularização só deve ser adicionado à função de custo no treinamento, avaliando a métrica de performance sem regularização no momento do teste.\n",
        "\n",
        "O hiperparâmetro ${\\alpha}$ é responsável por controlar o quão regularizado será o modelo:\n",
        "\n",
        "\n",
        "*   Se ${\\alpha} = 0$, não há regularização.\n",
        "*   Se ${\\alpha}$ for muito alto, então todos os pesos ficam perto de zero e o resultado é uma linha passando pela média dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmWFn2Ti49yZ",
        "colab_type": "text"
      },
      "source": [
        "#### Lasso Regression\n",
        "\n",
        "A regressão Lasso é uma outra forma de regularizar a regressão Linear. Assim como a Ridge, adicionamos um termo de regularização à função de custo do modelo. Este termo é dado por:\n",
        "\n",
        " $J(\\theta) = MSE(\\theta) +{\\alpha} {\\sum_{i=1}^{n}} = {|{\\theta}_i|}$.\n",
        "\n",
        "Uma característica importante da regressão Lasso é que ela tende a eliminar completamente os pesos das *features menos importantes*, até mesmo zerando-as. Assim, é possível usar esse tipo de técnica para realizar a seleção de features automaticamente, retornando um modelo esparso (ou seja, com poucos pesos de features não-nulos).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra_xofvF4_oz",
        "colab_type": "text"
      },
      "source": [
        "#### Elastic Net\n",
        "\n",
        "Já o Elastic Net é um nível intermediário entre a regressão Ridge e Lasso. O termo de regularização nesse caso é uma simples mistura dos termos das outras duas regressões, com uma variável $r$ que permite controlar a razão de mescla desses termos.\n",
        "\n",
        "\n",
        "*   Quando $r = 0$, o Elastic Net é equivalente à Ridge Regression.\n",
        "*   Quando $r = 1$, o Elastic Net é equivalente à Lasso Regression.\n",
        "\n",
        "Esse termo então fica com a fórmula:\n",
        "\n",
        "$J(\\theta) = MSE(\\theta) +{{r \\alpha \\sum_{i=1}^n | \\theta _i |} + {\\frac{1-r}{2}}\\alpha \\sum_{i=1}^n \\theta^2 _i}$\n",
        "\n",
        "Geralmente é bom ter pelo menos um pouco de regularização no modelo, então prefere-se evitar a regressão Linear simples. Mas como escolher entre todas essas opções?\n",
        "\n",
        "A regressão Ridge é um bom padrão, mas a Lasso e Elastic Net são mais recomendadas, pois elas tendem a reduzir o peso das features inúteis a zero, como discutido anteriormente. Contudo, a Elastic Net é preferida ao invés da Lasso, pois essa segunda pode ter resultados inesperados se o número de features for maior que o tamanho do set de treino ou quando várias features são fortemente correlacionadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpbmd0QuSDNz",
        "colab_type": "text"
      },
      "source": [
        "### Logito\n",
        "\n",
        "Algo importante de se notar é a implementação do logito na variável `positive_rate`. Como essa variável dependente é uma porcentagem (ela está necessariamente no intervalo de 0 a 1) para os regressores lineares funcionarem bem foi preciso aplicar nela uma função chamada logito. Essa função transforma o intervalo de 0 a 1 em um de menos infinito a mais infinito. Matematicamente o logito é definido como:\n",
        "\n",
        "$$\n",
        "f(x) = log(\\frac{x}{1 - x})\n",
        "$$\n",
        "\n",
        "Tivemos de aplicar essa função, pois a regressão linear naturalmente nunca seria capaz de se adequar a curva da nossa variável, que se assemelha a uma função logística.\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "  <a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1200px-Logistic-curve.svg.png\" alt=\"Função logística\" height=\"300\" />\n",
        "  </a>\n",
        "  <figcaption> Função logística, imitando a curva do positive_rate - Clique para aumentar</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "Então, foi preciso aplicar o logito na variável dependente de todos os treinamentos, incluindo a Decision Tree e da Random Forest para poder comparar os resultados. Isso acontece pois, mesmo que esses dois últimos modelos não precisem do logito, o erro precisa ser equivalente para a comparação (todos os modelos tem que ter os mesmos dados de treino e validação).\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "  <a href=\"https://upload.wikimedia.org/wikipedia/commons/5/57/Logit.png\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/5/57/Logit.png\" alt=\"Função logito\" height=\"300\" />\n",
        "  </a>\n",
        "  <figcaption> Função do logito, tratando a variável positive_rate - Clique para aumentar</figcaption>\n",
        "  </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET3mJ9IypNhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(steam, steam_labels, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlCu6ZjYI_Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_reg = LinearRegression() # No caso, também fazemos uma regressão linear simples para efeitos de comparação\n",
        "tree_reg = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
        "forest_reg = RandomForestRegressor(n_estimators=10, random_state=RANDOM_SEED)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjzFtHPDDmwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logit(y):\n",
        "  delta = 1e-2\n",
        "  y = (1-2*delta)*y + delta\n",
        "  return np.log(y/(1-y))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_wYdQPJpNpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e350259-f206-4659-c447-b760fb5fd3e8"
      },
      "source": [
        "# Regressão linear simples\n",
        "lin_reg.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg.predict(X_validate)\n",
        "lin_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Linear: RMSE = {:.2f}'.format(lin_rmse))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Linear: RMSE = 27007610.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-txYYOWp-lB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd105678-1ec7-45a1-e347-8e74c293c089"
      },
      "source": [
        "# Regressor Decision Tree\n",
        "tree_reg.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = tree_reg.predict(X_validate)\n",
        "tree_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Decision Tree: RMSE = {}'.format(tree_rmse))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Decision Tree: RMSE = 2.171469963992391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnIz62e9vl6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "043ef004-0d64-4066-a948-e070e5e29b3a"
      },
      "source": [
        "# Regressor Random Forest\n",
        "\n",
        "forest_reg.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = forest_reg.predict(X_validate)\n",
        "forest_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Random Forest: RMSE = {}'.format(forest_rmse))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Random Forest: RMSE = 1.7901463151352213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM0wVwSdl1PD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modelos Lineares regularizados (Ridge, Lasso e Elastic Net)\n",
        "alpha = 0.1\n",
        "\n",
        "lin_reg_ridge = Ridge(alpha=alpha)\n",
        "lin_reg_lasso = Lasso(alpha=alpha)\n",
        "lin_reg_elastic = ElasticNet(alpha=alpha, l1_ratio=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j5uAcOlnFg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dad9625-f92a-49ae-e4c1-ea4efb426aca"
      },
      "source": [
        "# Ridge\n",
        "lin_reg_ridge.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_ridge.predict(X_validate)\n",
        "lin_reg_ridge_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Ridge): RMSE = {}'.format(lin_reg_ridge_rmse))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Ridge): RMSE = 1.744043074407111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikex5TYKnYKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "281d33bf-2c5d-4873-e696-43672f2c12b0"
      },
      "source": [
        "# Lasso\n",
        "lin_reg_lasso.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_lasso.predict(X_validate)\n",
        "lin_reg_lasso_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Lasso: RMSE = {}'.format(lin_reg_lasso_rmse))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Lasso: RMSE = 1.7443117322877957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg9K5Wk3LeZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sorted(lin_reg_lasso.coef_, reverse=True)\n",
        "# lin_reg_lasso.intercept_\n",
        "# y_train.mean()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0wlW-aTnprf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cd7b1f7-8343-4cb5-f17c-b3a53232f008"
      },
      "source": [
        "# Elastic Net\n",
        "lin_reg_elastic.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_elastic.predict(X_validate)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Elastic Net: RMSE = 1.7341531103795031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTUAYmYGwbcJ",
        "colab_type": "text"
      },
      "source": [
        "Nesse projeto, optamos por utilizar a métrica do erro quadrático médio (Root Mean Square Error ou, simplesmente, RMSE). Essa métrica é a raiz do erro médio quadrático da diferença entre o valor predito e o valor observado. Assim, quanto menor esse valor, menor é a diferença entre o valor previsto e o valor observado. Podemos pensar nela como sendo uma medida análoga ao desvio padrão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdW8MJQ4uXaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "412e0f43-97c6-4fb1-acb0-246c47eb8001"
      },
      "source": [
        "print('Regressão Linear: RMSE = {:.2f}'.format(lin_rmse))\n",
        "print('Regressão Decision Tree: RMSE = {}'.format(tree_rmse))\n",
        "print('Regressão Random Forest: RMSE = {}'.format(forest_rmse))\n",
        "print('Regressão Ridge: RMSE = {}'.format(lin_reg_ridge_rmse))\n",
        "print('Regressão Lasso: RMSE = {}'.format(lin_reg_lasso_rmse))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Linear: RMSE = 27007610.54\n",
            "Regressão Decision Tree: RMSE = 2.171469963992391\n",
            "Regressão Random Forest: RMSE = 1.7901463151352213\n",
            "Regressão Ridge: RMSE = 1.744043074407111\n",
            "Regressão Lasso): RMSE = 1.7443117322877957\n",
            "Regressão Elastic Net): RMSE = 1.7341531103795031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu_b2pAbIiel",
        "colab_type": "text"
      },
      "source": [
        "Como pudemos observar, o menor RMSE gerado foi dado pela regressão Elastic Net. Por isso, vamos tentar entender melhor esse modelo, analisando seus coeficientes e outros resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLAneO8GDda",
        "colab_type": "text"
      },
      "source": [
        "### Análise do Elastic Net\n",
        "\n",
        "Como escolhemos a regressão Elastic Net para estudar nosso problema, vamos fazer algumas análises nessa seção."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewxP3bW1EMiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b9699c30-e089-42c9-bcde-81ba1d92555c"
      },
      "source": [
        "sorted(lin_reg_elastic.coef_, reverse=True)[:20]\n",
        "# lin_reg_elastic.intercept_\n",
        "# y_train.mean()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04875915495857794,\n",
              " 0.04586406651975248,\n",
              " 0.019367558849264537,\n",
              " 0.012926374618254702,\n",
              " 0.007818717061594618,\n",
              " 2.046916117911968e-05,\n",
              " -0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " -0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " -0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mnXLNodHkSx",
        "colab_type": "text"
      },
      "source": [
        "Observando os coeficientes, parece que o alpha escolhido ficou muito alto! De todas as features que estávamos lidando (aprox 8000), apenas algumas (6) estão fazendo efeito no modelo. Isso significa que provavelmente o regressor está apenas fazendo uma linha na média. Vamos tentar diminuir esse alpha para ajustar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJbZxN7hICac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha2 = 0.01\n",
        "alpha3 = 0.001\n",
        "alpha4 = 0.0001\n",
        "alpha5 = 0.00001\n",
        "lin_reg_elastic2 = ElasticNet(alpha=alpha2, l1_ratio=0.5, random_state=RANDOM_SEED)\n",
        "lin_reg_elastic3 = ElasticNet(alpha=alpha3, l1_ratio=0.5, random_state=RANDOM_SEED)\n",
        "lin_reg_elastic4 = ElasticNet(alpha=alpha4, l1_ratio=0.5, random_state=RANDOM_SEED, max_iter=6000)\n",
        "lin_reg_elastic5 = ElasticNet(alpha=alpha5, l1_ratio=0.5, random_state=RANDOM_SEED, max_iter=3000)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHd-o0fNIX0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4382020-722f-49ca-fdef-5b3219da9a9f"
      },
      "source": [
        "lin_reg_elastic2.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_elastic2.predict(X_validate)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Elastic Net: RMSE = 1.6967785826414756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9jhbRv3IcUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "723c4753-167e-472e-c230-dc889682e359"
      },
      "source": [
        "sorted(lin_reg_elastic2.coef_, reverse=True)[:20]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6526051101353807,\n",
              " 0.3386789028135034,\n",
              " 0.2775634439749966,\n",
              " 0.18685875083551484,\n",
              " 0.1825740863012459,\n",
              " 0.1322044851872361,\n",
              " 0.1298314401215881,\n",
              " 0.10634923658832784,\n",
              " 0.06749445017800593,\n",
              " 0.05895999688180234,\n",
              " 0.0543443419625155,\n",
              " 0.022347147727132782,\n",
              " 0.011564137184059686,\n",
              " 0.002977913673370434,\n",
              " 2.6404125371477827e-05,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVx2vg6LIfRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4ac3f23-9a57-4659-f51f-13091014ee71"
      },
      "source": [
        "lin_reg_elastic3.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_elastic3.predict(X_validate)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Elastic Net: RMSE = 1.6673583561445564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAP1Cn1CIfuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "562f79d1-c37a-4c54-db3a-e9dfbb1bc40a"
      },
      "source": [
        "sorted(lin_reg_elastic3.coef_, reverse=True)[:20]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4842564628014658,\n",
              " 0.6544713748586815,\n",
              " 0.5960026655281212,\n",
              " 0.5496947873322934,\n",
              " 0.528710729936831,\n",
              " 0.5287107298928807,\n",
              " 0.5275204179612393,\n",
              " 0.45707402993040563,\n",
              " 0.43327255001792114,\n",
              " 0.4292229269155247,\n",
              " 0.41412004848872086,\n",
              " 0.41027100138824385,\n",
              " 0.40801269095140935,\n",
              " 0.4013095403379067,\n",
              " 0.39625338069636673,\n",
              " 0.3759320964071202,\n",
              " 0.37509900987109274,\n",
              " 0.35901787480268266,\n",
              " 0.33519800606060063,\n",
              " 0.3345389039975558]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy6vBYHIIfzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dae3f332-d66d-46b6-c01c-456925e908f3"
      },
      "source": [
        "lin_reg_elastic4.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_elastic4.predict(X_validate)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Elastic Net: RMSE = 1.6478007382306028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-3j5QoIgDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d4d53c94-054c-4480-a03b-4484059bcdff"
      },
      "source": [
        "sorted(lin_reg_elastic4.coef_, reverse=True)[:20]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9955157166836397,\n",
              " 1.9849345550609319,\n",
              " 1.947705706631836,\n",
              " 1.943629816097248,\n",
              " 1.9182493753953629,\n",
              " 1.8634417602215068,\n",
              " 1.8506299655666063,\n",
              " 1.785703793802888,\n",
              " 1.7288951872340932,\n",
              " 1.7211373424446124,\n",
              " 1.7003621405192133,\n",
              " 1.6155001141268015,\n",
              " 1.5695810858101136,\n",
              " 1.5338203877240615,\n",
              " 1.5258749977327768,\n",
              " 1.4997079113491083,\n",
              " 1.4985613349447309,\n",
              " 1.4916439856498631,\n",
              " 1.490534103010945,\n",
              " 1.4564193763965303]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r38NfSvFMAj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c7828050-148c-4241-dbb0-765ab7c2a747"
      },
      "source": [
        "lin_reg_elastic5.fit(X_train, logit(y_train))\n",
        "\n",
        "y_pred = lin_reg_elastic5.predict(X_validate)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(y_validate), y_pred))\n",
        "print('Regressão Elastic Net: RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Elastic Net: RMSE = 1.7353045070392998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13460.73735863479, tolerance: 5.2899485249496125\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiUfkROdMAhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f93da750-3a77-4511-a6bb-63ff03068f50"
      },
      "source": [
        "sorted(lin_reg_elastic5.coef_, reverse=True)[:20]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.9621012008682723,\n",
              " 3.950853482109427,\n",
              " 3.943132629761766,\n",
              " 3.712929521318381,\n",
              " 3.669639130364649,\n",
              " 3.349629983447282,\n",
              " 3.3465592414017062,\n",
              " 3.3099360874433432,\n",
              " 3.301827824824555,\n",
              " 3.2593288429200276,\n",
              " 3.2455826122314066,\n",
              " 3.209562849039672,\n",
              " 3.1579639239415074,\n",
              " 3.14676052179382,\n",
              " 3.1438393706790784,\n",
              " 3.0973480452080313,\n",
              " 3.0916247435592767,\n",
              " 3.08920069179739,\n",
              " 3.082414185391904,\n",
              " 3.0710850342626816]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEMb99Sdbnhy",
        "colab_type": "text"
      },
      "source": [
        "Após esse ajuste manual de hiperparâmetros, o melhor alpha encontrado foi de 0.0001. Um valor menor que esse fez com que o modelo tivesse dificuldades para convergir.\n",
        "\n",
        "A partir disso, mais features estão sendo levadas em conta no modelo e poderemos estudar melhor essas features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZgZsm6_IQ4Q",
        "colab_type": "text"
      },
      "source": [
        "# Score Final e Salvando o modelo\n",
        "\n",
        "Aqui, vamos verificar o score final (ou erro final) do nosso modelo Elastic Net com os hiperparâmetros ajustados. O modelo, então, é treinado com os dados de treino e testado com os dados de teste. \n",
        "\n",
        "Por fim, treinamos o modelo com todos os dados disponíveis juntos e salvamos o modelo para a aplicação e uso posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBamtOirIXLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33be1899-f796-4c17-d63e-0bcabf2e536d"
      },
      "source": [
        "lin_reg_elastic4.fit(steam, logit(steam_labels))\n",
        "\n",
        "# Variáveis independentes: dataset original menos a coluna de valores dependentes.\n",
        "test_steam = strat_test_set.drop([\"positive_rate\"], axis=1)\n",
        "\n",
        "# Variável dependente, também chamada de label.\n",
        "test_steam_labels = strat_test_set[\"positive_rate\"].copy()\n",
        "\n",
        "y_pred = lin_reg_elastic4.predict(test_steam)\n",
        "lin_reg_elastic_rmse = np.sqrt(mean_squared_error(logit(test_steam_labels), y_pred))\n",
        "print('Score final (Regressão Elastic Net): RMSE = {}'.format(lin_reg_elastic_rmse))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score final (Regressão Elastic Net): RMSE = 1.63598171623662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQe0F747QnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9da3ff1e-e10d-4a24-d44c-2f4ef9b2e4f1"
      },
      "source": [
        "# separação do X e y de todos os dados disponíveis\n",
        "\n",
        "# Variáveis independentes: dataset original menos a coluna de valores dependentes.\n",
        "all_steam = df.drop([\"positive_rate\"], axis=1)\n",
        "\n",
        "# Variável dependente, também chamada de label.\n",
        "all_steam_labels = df[\"positive_rate\"].copy()\n",
        "\n",
        "lin_reg_elastic4.fit(all_steam, logit(all_steam_labels))\n",
        "\n",
        "#salvando o modelo final\n",
        "dump(lin_reg_elastic4, 'steam_positive_rate_predictor.joblib')\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['steam_positive_rate_predictor.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2o8emCN2li",
        "colab_type": "text"
      },
      "source": [
        "Vale lembrar que o modelo foi treinado para prever o *logito* da razão de *reviews* positivas. Para usar o modelo, após prever o logito, basta aplicar nele a função logística descrita pela fórmula abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E3KfeS8OP48",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYwndL8WlMnf",
        "colab_type": "text"
      },
      "source": [
        "# Importância das Características\n",
        "\n",
        "Antes de analisar os coeficientes do Elastic Net, vamos utilizar uma importante ferramenta da Random Forest para ter mais insights. Esse modelo possibilita verificar os pesos de cada feature para a predição. Esses pesos são dados pela `feature_importances_`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ouUv_xAlNr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f53c5cf-2b16-48de-9802-3ab826bf2f97"
      },
      "source": [
        "forest_reg.fit(steam, steam_labels)\n",
        "feature_importances = forest_reg.feature_importances_\n",
        "feature_importances"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.11704297e-03, 1.03867931e-01, 1.34483327e-02, ...,\n",
              "       9.56536652e-04, 5.27607465e-05, 1.27067366e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB2AC4cb7Qpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "354b86dd-c29e-482d-85de-670a557aad62"
      },
      "source": [
        "attribs = list(steam)\n",
        "sorted(zip(feature_importances, attribs), reverse=True)[:20]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.11518398098610597, 'price'),\n",
              " (0.10386793127885081, 'achievements'),\n",
              " (0.015296392972570932, 'pub_others'),\n",
              " (0.014841605719025713, 'genres_Casual'),\n",
              " (0.014402980481293213, 'tags_Action'),\n",
              " (0.014014916766343064, 'platform_mac'),\n",
              " (0.013832122954315578, 'median_playtime'),\n",
              " (0.013465773156250813, 'dev_others'),\n",
              " (0.013448332654028849, 'average_playtime'),\n",
              " (0.013216795922926444, 'tags_Casual'),\n",
              " (0.012667520525909779, 'tags_Adventure'),\n",
              " (0.012459535608621865, 'tags_Indie'),\n",
              " (0.012361762541313614, 'genres_Adventure'),\n",
              " (0.011989562804269905, 'genres_Indie'),\n",
              " (0.011634716772857797, 'genres_Action'),\n",
              " (0.011581159334421456, 'genres_Simulation'),\n",
              " (0.010901349822229376, 'genres_RPG'),\n",
              " (0.010639164765735882, 'genres_Strategy'),\n",
              " (0.010126997220305281, 'platform_linux'),\n",
              " (0.009831971986479598, 'tags_Strategy')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ectv579Gk-p",
        "colab_type": "text"
      },
      "source": [
        "Como observado, as 10 características que mais afetam nossa variável dependente são:\n",
        "  1. o preço\n",
        "  2. a quantidade de *achievements* (conquistas)\n",
        "  3. ser de um *publisher* pequeno (de apenas 1 jogo)\n",
        "  4. ser do gênero: Casual\n",
        "  5. ter o tag: Ação\n",
        "  6. a mediana do tempo de jogado pelos usuários\n",
        "  7. estar disponível para a plataforma mac\n",
        "  8. ter o tag: Casual\n",
        "  9. a média do tempo de jogado pelos usuários\n",
        "  10. ser de um *developer* pequeno (de apenas 1 jogo)\n",
        "\n",
        "Temos destaque para preço e conquistas, que possuem uma ordem de grandeza superior às outras características. Infelizmente, não é possível extrair disso a informação sobre se essas características afetam positivamente ou negativamente o score final, somente que elas são importantes. Essa é uma limitação da Random Forest.\n",
        "\n",
        "Contudo, podemos inferir algumas coisas sobre as duas primeiras características. O preço muitas vezes pode estar ligado a jogos Free-To-Play que estão ganhando muita popularidade devido às suas [microtransações](https://en.wikipedia.org/wiki/Microtransaction). Alguns jogos grátis com conteúdo extra pago são: Counter-Strike: Global Offensive, Dota 2 e o próprio Fornite (apesar desse último não ser da Steam). Esses exemplos são os jogos mais rentáveis da história do mercado de games.\n",
        "\n",
        "Ainda, a presença de conquistas (*achievements*) como uma característica forte na influência do sucesso do jogo pode ser devido ao ato de **zerar** (ou **platinar**) o jogo. Para jogadores *hardcore* essas conquistas são bastante atrativas, pois geralmente eles tentam fazer todas, independentemente da dificuldade. É o exemplo da série Dark Souls, jogos com diversas conquistas e dificuldade elevadíssima, também extremamente rentáveis e populares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmPOKdgdkrvR",
        "colab_type": "text"
      },
      "source": [
        "### Análise dos coeficientes do modelo final\n",
        "\n",
        "Finalmente, vamos analisar os coeficientes dos pesos do nosso modelo gerado no projeto. Aqui, quanto maior o coeficiente, maior seu peso e consequentemente, maior o impacto dessa variável nas predições do modelo. Assim, podemos separar que variáveis são mais importantes para o sucesso de um jogo na Steam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3L4ZuOnky4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "fd303295-a6ab-43ab-e065-2ac6240d1694"
      },
      "source": [
        "attribs = list(steam)\n",
        "sorted(zip(lin_reg_elastic4.coef_, attribs), reverse=True)[:30]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7054550327144805, 'pub_Big Fish Games'),\n",
              " (0.5710731506525448, 'dev_Tiny Warrior Games'),\n",
              " (0.5393312927813543, 'pub_Excalibur Publishing'),\n",
              " (0.5182562979482962, 'dev_Wastelands Interactive'),\n",
              " (0.4909605910075704, 'pub_Dikobraz Games'),\n",
              " (0.47554494754037246, 'pub_NekoNyan Ltd.'),\n",
              " (0.4531040420681427, 'dev_CHARON'),\n",
              " (0.44475196568500275, 'dev_IGGYMOB Co.,Ltd'),\n",
              " (0.4438689608650628, 'pub_Astronomic Games'),\n",
              " (0.4366837829668376, 'dev_VERTEX HORIZON'),\n",
              " (0.4296845953363248, 'pub_Oh, a Rock! Studios'),\n",
              " (0.42706748369123515, 'dev_Workroom7'),\n",
              " (0.42444014770598765, 'dev_Flying Panjandrum / ふらいんぐパンジャンドラム'),\n",
              " (0.4244401398542611, 'pub_Flying Panjandrum / ふらいんぐパンジャンドラム'),\n",
              " (0.4236549578491766, 'dev_Visual Concepts'),\n",
              " (0.4224955281231739, 'dev_Adept Studios GD'),\n",
              " (0.40609617503393697, 'pub_VT Publishing'),\n",
              " (0.39519337750072553, 'pub_Light Maze'),\n",
              " (0.3937568845465052, 'dev_SpielmannSpiel'),\n",
              " (0.3910167214379752, 'dev_Andy Jurko'),\n",
              " (0.3910166688527639, 'pub_Andy Jurko'),\n",
              " (0.38642621655194065, 'pub_United Independent Entertainment GmbH'),\n",
              " (0.3850282468267284, 'dev_TACS Games'),\n",
              " (0.3826161909529456, 'pub_RevolutionGT'),\n",
              " (0.37353297637596783, 'dev_Lost Astronaut Studios'),\n",
              " (0.3657433171763111, 'dev_Nekyau Games'),\n",
              " (0.3651803893064411, 'dev_Kedronic UAB'),\n",
              " (0.36518035571418156, 'pub_Kedronic UAB'),\n",
              " (0.3649137602278608, 'pub_Mongoose Net Ltd.'),\n",
              " (0.3598147364787075, 'dev_Activision')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9h6qQKBzTtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "1637ebc3-069e-42f7-d072-8d7e081c4f75"
      },
      "source": [
        "sorted(zip(lin_reg_elastic4.coef_, attribs))[:30]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-0.7162706537449347, 'dev_Big Fish Games'),\n",
              " (-0.46746911702874894, 'pub_轻文'),\n",
              " (-0.42074932195208653, 'tags_Colorful'),\n",
              " (-0.3872336769801989, 'dev_Big Fish Studios'),\n",
              " (-0.3612733518823536, 'pub_Konstructors Entertainment'),\n",
              " (-0.35873528929426474, 'dev_Terminal Reality'),\n",
              " (-0.33972758148190196, 'tags_Chess'),\n",
              " (-0.31701437538864596, 'dev_Remedy Entertainment'),\n",
              " (-0.3131173121589584, 'tags_Controller'),\n",
              " (-0.3108001302058288, 'pub_Fat Dog Games'),\n",
              " (-0.30125796590818354, 'pub_RunServer'),\n",
              " (-0.30045544046825995, 'tags_Software'),\n",
              " (-0.2994396253795674, 'pub_SNK CORPORATION'),\n",
              " (-0.2873687097073155, 'dev_MyDreamForever_Old'),\n",
              " (-0.2868705866658524, 'pub_PopCap Games, Inc.'),\n",
              " (-0.2782884692658463, 'dev_Toyman Interactive'),\n",
              " (-0.27471891955935757, 'pub_Fruitbat Factory'),\n",
              " (-0.27368604980805294, 'pub_OtakuMaker.com'),\n",
              " (-0.27078533189246445, 'pub_Another Indie'),\n",
              " (-0.2705181233216176, 'tags_Choose Your Own Adventure'),\n",
              " (-0.26549397039653555, 'pub_Kagura Games'),\n",
              " (-0.2628644565618265, 'pub_Tri Synergy, Inc.'),\n",
              " (-0.2609290560343677, 'pub_Kiss Publishing Ltd'),\n",
              " (-0.2606577793114355, 'pub_Grove Street Games'),\n",
              " (-0.2606577609362608, 'dev_Grove Street Games'),\n",
              " (-0.2527413777541312, 'dev_Flying. Stone. Production'),\n",
              " (-0.2514708458856678, 'pub_Adult Swim Games'),\n",
              " (-0.248656114736063, 'dev_Somer Games'),\n",
              " (-0.24826818194870146, 'tags_Classic'),\n",
              " (-0.24426714708126546, 'pub_Sysdia Games')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqMvN0gPo6lz",
        "colab_type": "text"
      },
      "source": [
        "Aqui fizemos duas ordenações: as variáveis com mais peso *positivo* e aquelas com mais peso *negativo* nas predições. Assim, temos duas listas com as 30 features mais importantes de cada segmento.\n",
        "\n",
        "Curiosamente, um jogo publicado pela Big Fish Games é relevante para o sucesso dele, mas se ele foi desenvolvido por essa empresa, é relevante para seu **fracasso**.\n",
        "\n",
        "Agora, podemos observar que muitas dessas features são de `developers & publishers`. Para verificar as outras features, vamos remover os devs e pubs da comparação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mBDAQxDkrAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "fd5c69c6-d0f8-41a6-f78c-648fb38e032b"
      },
      "source": [
        "# tirando os pubs e devs para ver o resto\n",
        "i = 0\n",
        "for e in sorted(zip(lin_reg_elastic4.coef_, attribs), reverse=True):\n",
        "  if e[1][:3] != 'dev' and e[1][:3] != 'pub':\n",
        "    i += 1\n",
        "    print(e)\n",
        "  if i == 30:\n",
        "    break"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.2712187265716437, 'tags_VR Only')\n",
            "(0.22223491702211984, 'genres_Early Access')\n",
            "(0.20848883802997392, 'tags_3D')\n",
            "(0.19999926510803753, 'owners_0-20000')\n",
            "(0.18808866368982724, 'tags_Procedural Generation')\n",
            "(0.18518101043985427, 'tags_Romance')\n",
            "(0.1763372231164349, 'genres_Accounting')\n",
            "(0.16440150382486823, 'tags_Baseball')\n",
            "(0.09819952861570692, 'tags_MMORPG')\n",
            "(0.08780082361432998, 'tags_Utilities')\n",
            "(0.08274113870330922, 'tags_Puzzle-Platformer')\n",
            "(0.08175575850807652, 'age_18')\n",
            "(0.07371735742300371, 'genres_Racing')\n",
            "(0.07072468365736083, 'tags_Comic Book')\n",
            "(0.06937333164917366, 'tags_Top-Down Shooter')\n",
            "(0.04868080805815167, 'age_0')\n",
            "(0.048029260453103274, 'tags_Match 3')\n",
            "(0.04153640149793453, 'genres_Massively Multiplayer')\n",
            "(0.03275739820271361, 'tags_Villain Protagonist')\n",
            "(0.028312305480543573, 'tags_Medieval')\n",
            "(0.024628256322050505, 'genres_Gore')\n",
            "(0.020125540909120842, 'tags_Sokoban')\n",
            "(0.019897457037631218, 'tags_Action RPG')\n",
            "(0.018951978709579556, 'tags_Cute')\n",
            "(0.016685952004360325, 'owners_50000-100000')\n",
            "(0.016112453961087334, 'genres_Nudity')\n",
            "(0.014820998363374692, 'owners_10000000-20000000')\n",
            "(0.014816962375189755, 'owners_200000-500000')\n",
            "(0.013367620321627045, 'tags_Driving')\n",
            "(0.009760295625059043, 'genres_Design & Illustration')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9zw04Bzkri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "49b00714-e1bb-4cee-ec68-e86d692a05b9"
      },
      "source": [
        "# tirando os pubs e devs para ver o resto (negativos)\n",
        "i = 0\n",
        "for e in sorted(zip(lin_reg_elastic4.coef_, attribs)):\n",
        "  if e[1][:3] != 'dev' and e[1][:3] != 'pub':\n",
        "    i += 1\n",
        "    print(e)\n",
        "  if i == 30:\n",
        "    break"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.42074932195208653, 'tags_Colorful')\n",
            "(-0.33972758148190196, 'tags_Chess')\n",
            "(-0.3131173121589584, 'tags_Controller')\n",
            "(-0.30045544046825995, 'tags_Software')\n",
            "(-0.2705181233216176, 'tags_Choose Your Own Adventure')\n",
            "(-0.24826818194870146, 'tags_Classic')\n",
            "(-0.24385923229651307, 'tags_Hacking')\n",
            "(-0.23964109088648838, 'tags_Card Game')\n",
            "(-0.2391005066929292, 'tags_2D Fighter')\n",
            "(-0.22676829581909216, 'tags_Tanks')\n",
            "(-0.2227623809502472, 'tags_Exploration')\n",
            "(-0.2196013863481163, 'genres_Video Production')\n",
            "(-0.21749537234655794, 'tags_Robots')\n",
            "(-0.21199223998835887, 'tags_Early Access')\n",
            "(-0.20698159482277143, 'tags_Rhythm')\n",
            "(-0.20272052250722813, 'tags_World War I')\n",
            "(-0.19927932730658934, 'tags_Choices Matter')\n",
            "(-0.19759617256691972, 'tags_Mechs')\n",
            "(-0.18697829530672552, 'genres_Utilities')\n",
            "(-0.18175492860707054, 'tags_Local Multiplayer')\n",
            "(-0.18147641747276588, 'tags_3D Platformer')\n",
            "(-0.1809756907391874, 'tags_Programming')\n",
            "(-0.17330354668656892, 'tags_Time Management')\n",
            "(-0.1730360694783581, 'tags_Gore')\n",
            "(-0.17265488007369806, 'tags_Anime')\n",
            "(-0.17231160883921642, 'tags_Audio Production')\n",
            "(-0.17186040899360386, 'tags_Tower Defense')\n",
            "(-0.16713218097966767, 'tags_VR')\n",
            "(-0.16612790939823005, 'tags_Lemmings')\n",
            "(-0.16586288039628638, 'tags_Replay Value')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcVwli_KsM9k",
        "colab_type": "text"
      },
      "source": [
        "Como pudemos ver, algumas tags são importantes para o reconhecimento do jogo, enquanto outras geralmente atrapalham seu crescimento.\n",
        "\n",
        "Algo interessante de se notar é a presença de VR Only nos positivos e VR nos negativos, para designar jogos de Virtual Reality (realidade virtual). Isso pode ser causado pelo *hype* dos jogos de realidade virtual. Geralmente apenas [boas experiências](https://store.steampowered.com/app/546560/HalfLife_Alyx/) de VR são aceitas na loja da Steam, enquanto que jogos que apenas adicionam o suporte não possuem funcionalidades tão interessantes.\n",
        "\n",
        "Ainda, temos a presença de Early Access tanto no positivo quanto no negativo, o que pode ser devido ao fato dos jogos serem conteúdos ainda em versão beta. Há uma grande inconsistência nessa parte, pois existem jogos Early Access lotados de bugs e sem muitas funcionalidades, enquanto existem outros que já possuem uma maturidade maior e mais qualidade.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU0dgzFalPqr",
        "colab_type": "text"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "Finalmente, pudemos utilizar as técnicas de Machine Learning aprendidas em aula para construir um preditor do sucesso de um jogo da Steam com base nas suas características e fazer uma análise das características mais importantes para o sucesso (ou não) deles. \n",
        "\n",
        "Pudemos notar que o preço e conquistas são importantes fatores devido ao modelo de Random Forest e seu `feature_importances_`. Contudo, não conseguimos ter uma certeza do tipo de relação extraída aqui. Apesar de desconfiarmos dos jogos free-to-play e dos gamers que gostam de zerar os jogos, não temos uma certeza.\n",
        "\n",
        "Através do modelo de Elastic Net, pudemos verificar que algumas tags (ou categorias) dos jogos são positivas e negativas em relação ao sucesso:\n",
        "\n",
        "* Positivo: VR Only, Early Access, 3D, ..., poucos owners, Procedural Generation, Romance.\n",
        "\n",
        "* Negativo: Colorful, Chess, Controller, Software, ...,  VR.\n",
        "\n",
        "Aqui levantamos a causa dos jogos de Realidade Virtual e os jogos Early Access cuja qualidade de implementação varia, consequentemente mudando as reviews da comunidade.\n",
        "\n",
        "Apesar de não termos conclusões exatas sobre quais características são definitivas para o sucesso de um jogo da Steam, conseguimos extrair algumas análises interessantes do nosso projeto, abrindo espaço e auxiliando análises mais profundas ainda nesse mercado gigantesco.\n",
        "\n",
        "Como próximos passos do projeto, gostaríamos de abordar dois tópicos principais: o ajuste fino dos hiperparâmetros e cross-validation, além do chamado *Variable Ranking*.\n",
        "Como tivemos a limitação da RAM no projeto e não conseguimos rodar cross_val e o GridSearchCV, não foi possível construir os modelos da forma mais adequada possível, abrindo espaço para melhorias aqui.\n",
        "\n",
        "Além disso, gostaríamos de trabalhar melhor a técnica de *Variable Ranking*, que é o processo de ordernar as features pelo valor de alguma função de custo, que medirá a relevância das features pelo modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmyaixYddE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": []
    }
  ]
}